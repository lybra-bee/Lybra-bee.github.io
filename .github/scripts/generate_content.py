#!/usr/bin/env python3
import os
import json
import requests
import random
from datetime import datetime, timezone
import shutil
import re
import textwrap
from PIL import Image, ImageDraw, ImageFont
import time
import logging
import argparse
import base64

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ======== –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–º—ã ========
def generate_ai_trend_topic():
    current_trends_2025 = [
        "Multimodal AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞—É–¥–∏–æ –≤ –µ–¥–∏–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö",
        "AI –∞–≥–µ–Ω—Ç—ã –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å–ø–æ—Å–æ–±–Ω—ã–µ –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏",
        "–ö–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ä—ã–≤ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
        "–ù–µ–π—Ä–æ–º–æ—Ä—Ñ–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–Ω–µ—Ä–≥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π",
        "Generative AI —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫–æ–¥–∞ –∏ –¥–∏–∑–∞–π–Ω–æ–≤ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º",
        "Edge AI –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –±–µ–∑ –æ–±–ª–∞—á–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏",
        "AI –¥–ª—è –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç —É–≥—Ä–æ–∑",
        "–≠—Ç–∏—á–Ω—ã–π AI –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
        "AI –≤ healthcare –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ª–µ–∫–∞—Ä—Å—Ç–≤ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω–∞",
        "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞",
        "AI –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∂–∞—Ç–∏–µ –º–æ–¥–µ–ª–µ–π –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ inference",
        "–î–æ–≤–µ—Ä–µ–Ω–Ω—ã–π AI –æ–±—ä—è—Å–Ω–∏–º—ã–µ –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã",
        "AI –¥–ª—è –∫–ª–∏–º–∞—Ç–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –∏ —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è",
        "–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–∏—Ñ—Ä–æ–≤—ã–µ –ø–æ–º–æ—â–Ω–∏–∫–∏",
        "AI –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—á–µ–±–Ω—ã–µ –ø–ª–∞–Ω—ã"
    ]
    application_domains = [
        "–≤ –≤–µ–± —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏ cloud native –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö",
        "–≤ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∏ IoT —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–∞—Ö –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –∞–Ω–∞–ª–∏–∑–µ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –±–∏–∑–Ω–µ—Å –∞–Ω–∞–ª–∏—Ç–∏–∫–µ",
        "–≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –∫–∏–±–µ—Ä–∑–∞—â–∏—Ç–µ",
        "–≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –∏ –±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö",
        "–≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ —Ñ–∏–Ω—Ç–µ—Ö–µ",
        "–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ smart city –∏ —É–º–Ω–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ",
        "–≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ EdTech"
    ]
    trend = random.choice(current_trends_2025)
    domain = random.choice(application_domains)
    topic_formats = [
        f"{trend} {domain} –≤ 2025 –≥–æ–¥—É",
        f"–¢–µ–Ω–¥–µ–Ω—Ü–∏–∏ 2025 {trend} {domain}",
        f"{trend} —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è {domain} –≤ 2025",
        f"–ö–∞–∫ {trend} —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç {domain} –≤ 2025 –≥–æ–¥—É",
        f"–ò–Ω–Ω–æ–≤–∞—Ü–∏–∏ 2025 {trend} –¥–ª—è {domain}",
        f"{trend} –±—É–¥—É—â–µ–µ {domain} –≤ 2025 –≥–æ–¥—É",
        f"–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ {trend} –≤ {domain} 2025"
    ]
    return random.choice(topic_formats)

# ======== –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å—Ç–∞—Ç–µ–π ========
def clean_old_articles(keep_last=3):
    logger.info(f"üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å—Ç–∞—Ç–µ–π, –æ—Å—Ç–∞–≤–ª—è–µ–º {keep_last} –ø–æ—Å–ª–µ–¥–Ω–∏—Ö...")
    content_dir = "content"
    if os.path.exists(content_dir):
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã, –æ—Å—Ç–∞–≤–ª—è—è –ø–æ—Å–ª–µ–¥–Ω–∏–µ keep_last
        posts_dir = os.path.join(content_dir, "posts")
        if os.path.exists(posts_dir):
            posts = sorted([f for f in os.listdir(posts_dir) if f.endswith('.md')], 
                          reverse=True)
            for post in posts[keep_last:]:
                os.remove(os.path.join(posts_dir, post))
                logger.info(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –ø–æ—Å—Ç: {post}")
    else:
        os.makedirs("content/posts", exist_ok=True)
        with open("content/_index.md", "w", encoding="utf-8") as f:
            f.write("---\ntitle: \"–ì–ª–∞–≤–Ω–∞—è\"\n---")
        with open("content/posts/_index.md", "w", encoding="utf-8") as f:
            f.write("---\ntitle: \"–°—Ç–∞—Ç—å–∏\"\n---")
        logger.info("‚úÖ –°–æ–∑–¥–∞–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ content")

# ======== –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ ========
def generate_content():
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    check_environment_variables()
    
    clean_old_articles()
    
    topic = generate_ai_trend_topic()
    logger.info(f"üìù –¢–µ–º–∞ —Å—Ç–∞—Ç—å–∏: {topic}")
    
    image_filename = generate_article_image(topic)
    content, model_used = generate_article_content(topic)
    
    date = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    slug = generate_slug(topic)
    filename = f"content/posts/{date}-{slug}.md"
    
    frontmatter = generate_frontmatter(topic, content, model_used, image_filename)
    
    os.makedirs("content/posts", exist_ok=True)
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(frontmatter)
    
    logger.info(f"‚úÖ –°—Ç–∞—Ç—å—è —Å–æ–∑–¥–∞–Ω–∞: {filename}")
    return filename

def check_environment_variables():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
    env_vars = {
        'OPENROUTER_API_KEY': os.getenv('OPENROUTER_API_KEY'),
        'GROQ_API_KEY': os.getenv('GROQ_API_KEY')
    }
    
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è:")
    for var_name, var_value in env_vars.items():
        status = "‚úÖ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω" if var_value else "‚ùå –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
        logger.info(f"   {var_name}: {status}")

# ======== –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ OpenRouter/Groq ========
def generate_article_content(topic):
    openrouter_key = os.getenv('OPENROUTER_API_KEY')
    groq_key = os.getenv('GROQ_API_KEY')
    models_to_try = []

    if groq_key:
        groq_models = ["llama-3.1-8b-instant", "llama-3.2-1b-preview", "llama-3.1-70b-versatile"]
        for model_name in groq_models:
            models_to_try.append((f"Groq-{model_name}", lambda m=model_name: generate_with_groq(groq_key, m, topic)))
    if openrouter_key:
        openrouter_models = ["anthropic/claude-3-haiku", "anthropic/claude-3-sonnet", "google/gemini-pro-1.5"]
        for model_name in openrouter_models:
            models_to_try.append((model_name, lambda m=model_name: generate_with_openrouter(openrouter_key, m, topic)))

    # –ï—Å–ª–∏ –Ω–µ—Ç API –∫–ª—é—á–µ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback
    if not models_to_try:
        logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö API –∫–ª—é—á–µ–π –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞")
        fallback = generate_fallback_content(topic)
        return fallback, "fallback-generator"

    for model_name, generate_func in models_to_try:
        try:
            logger.info(f"üîÑ –ü—Ä–æ–±—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–µ–∫—Å—Ç–∞: {model_name}")
            result = generate_func()
            if result and len(result.strip()) > 100:
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —á–µ—Ä–µ–∑ {model_name}")
                return result, model_name
            else:
                logger.warning(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç {model_name}")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ {model_name}: {e}")
            continue

    logger.warning("‚ö†Ô∏è –í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
    fallback = generate_fallback_content(topic)
    return fallback, "fallback-generator"

def generate_fallback_content(topic):
    """Fallback –∫–æ–Ω—Ç–µ–Ω—Ç –µ—Å–ª–∏ –≤—Å–µ API –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç"""
    sections = [
        f"# {topic}",
        "",
        "## –í–≤–µ–¥–µ–Ω–∏–µ",
        f"–¢–µ–º–∞ '{topic}' —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è increasingly important –≤ 2025 –≥–æ–¥—É. ",
        "",
        "## –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏",
        "- –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
        "- –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è AI –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ workflow",
        "- –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏",
        "",
        "## –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ",
        "–ö–æ–º–ø–∞–Ω–∏–∏ –≤–Ω–µ–¥—Ä—è—é—Ç AI —Ä–µ—à–µ–Ω–∏—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Å–≤–æ–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤.",
        "",
        "## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ",
        "–ë—É–¥—É—â–µ–µ –≤—ã–≥–ª—è–¥–∏—Ç promising —Å —Ä–∞–∑–≤–∏—Ç–∏–µ–º AI —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π.",
        "",
        "*–°—Ç–∞—Ç—å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏*"
    ]
    return "\n".join(sections)

def generate_with_groq(api_key, model_name, topic):
    prompt = f"""–ù–∞–ø–∏—à–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—É—é —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É: '{topic}' –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –§–æ—Ä–º–∞—Ç Markdown
- 400-600 —Å–ª–æ–≤
- –°—Ç—Ä—É–∫—Ç—É—Ä–∞: –≤–≤–µ–¥–µ–Ω–∏–µ, –æ—Å–Ω–æ–≤–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã, –∑–∞–∫–ª—é—á–µ–Ω–∏–µ
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å
- –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏ –∫–µ–π—Å—ã
"""
    resp = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
        json={
            "model": model_name, 
            "messages":[{"role":"user","content":prompt}], 
            "max_tokens": 2000,
            "temperature": 0.7,
            "top_p": 0.9
        },
        timeout=30
    )
    
    if resp.status_code == 200:
        data = resp.json()
        return data['choices'][0]['message']['content'].strip()
    else:
        raise Exception(f"Groq API error {resp.status_code}: {resp.text}")

def generate_with_openrouter(api_key, model_name, topic):
    prompt = f"""–ù–∞–ø–∏—à–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—É—é —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É: '{topic}' –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –§–æ—Ä–º–∞—Ç Markdown
- 400-600 —Å–ª–æ–≤
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏
- –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã
- –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–æ–Ω
"""
    resp = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers={
            "Authorization": f"Bearer {api_key}", 
            "Content-Type": "application/json",
            "HTTP-Referer": "https://ai-content-generator.com",
            "X-Title": "AI Content Generator"
        },
        json={
            "model": model_name, 
            "messages":[{"role":"user","content":prompt}], 
            "max_tokens": 2000,
            "temperature": 0.7,
            "top_p": 0.9
        },
        timeout=30
    )
    
    if resp.status_code == 200:
        data = resp.json()
        return data['choices'][0]['message']['content'].strip()
    else:
        raise Exception(f"OpenRouter API error {resp.status_code}: {resp.text}")

# ======== –ë–ï–°–ü–õ–ê–¢–ù–ê–Ø –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ========
def generate_article_image(topic):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ API"""
    logger.info(f"üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –ø—Ä–æ–º–ø—Ç—É: {topic}")
    
    prompt = f"{topic}, digital art, futuristic, AI technology, 4k, high quality, trending"
    
    # –°–∞–º—ã–µ –Ω–∞–¥–µ–∂–Ω—ã–µ –±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ API (–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ)
    reliable_apis = [
        try_craiyon,            # Craiyon (DALL-E mini) - —Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π
        try_deepai_public,      # DeepAI —Å –ø—É–±–ª–∏—á–Ω—ã–º –∫–ª—é—á–æ–º
        try_huggingface_public, # Hugging Face –ø—É–±–ª–∏—á–Ω—ã–µ –º–æ–¥–µ–ª–∏
        try_quickai,           # QuickAI
        try_proxyfusion,       # ProxyFusion
        try_openart,           # OpenArt
        try_local_sd,          # –õ–æ–∫–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ API
        try_stability_public   # Stability AI –ø—É–±–ª–∏—á–Ω—ã–π
    ]
    
    # –ü—Ä–æ–±—É–µ–º —Å–∞–º—ã–µ –Ω–∞–¥–µ–∂–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã
    for api_func in reliable_apis:
        try:
            logger.info(f"üîÑ –ü—Ä–æ–±—É–µ–º {api_func.__name__}")
            result = api_func(prompt[:150], topic)
            if result:
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —á–µ—Ä–µ–∑ {api_func.__name__}")
                return result
            time.sleep(1)
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ {api_func.__name__}: {e}")
            continue
    
    # –ï—Å–ª–∏ –≤—Å–µ API –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π placeholder
    logger.warning("‚úÖ –í—Å–µ API –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π placeholder")
    return generate_enhanced_placeholder(topic)

def try_craiyon(prompt, topic):
    """Craiyon (–±—ã–≤—à–∏–π DALL-E mini) - —Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π"""
    try:
        logger.info("üé® Craiyon –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        response = requests.post(
            "https://api.craiyon.com/v3",
            json={"prompt": prompt},
            timeout=30
        )
        
        if response.status_code == 200:
            data = response.json()
            if data.get("images"):
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –ø–µ—Ä–≤—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É –∏–∑ base64
                image_data = base64.b64decode(data["images"][0])
                return save_image_bytes(image_data, topic)
    except Exception as e:
        logger.error(f"‚ùå Craiyon error: {e}")
    return None

def try_deepai_public(prompt, topic):
    """DeepAI —Å –ø—É–±–ª–∏—á–Ω—ã–º –∫–ª—é—á–æ–º"""
    try:
        logger.info("üé® DeepAI –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        response = requests.post(
            "https://api.deepai.org/api/text2img",
            headers={'api-key': 'quickstart-credential'},
            data={'text': prompt},
            timeout=25
        )
        
        if response.status_code == 200:
            data = response.json()
            if data.get('output_url'):
                return save_image_from_url(data['output_url'], topic)
    except Exception as e:
        logger.error(f"‚ùå DeepAI error: {e}")
    return None

def try_huggingface_public(prompt, topic):
    """Hugging Face –ø—É–±–ª–∏—á–Ω—ã–µ –º–æ–¥–µ–ª–∏"""
    try:
        logger.info("üé® Hugging Face –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏
        models = [
            "runwayml/stable-diffusion-v1-5",
            "stabilityai/stable-diffusion-2-1",
            "prompthero/openjourney-v4"
        ]
        
        for model in models:
            try:
                response = requests.post(
                    f"https://api-inference.huggingface.co/models/{model}",
                    json={"inputs": prompt},
                    timeout=30
                )
                if response.status_code == 200:
                    return save_image_bytes(response.content, topic)
            except:
                continue
    except Exception as e:
        logger.error(f"‚ùå HF error: {e}")
    return None

def try_quickai(prompt, topic):
    """QuickAI API"""
    try:
        logger.info("üé® QuickAI –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        response = requests.post(
            "https://api.quickai.io/api/v1/generate",
            json={"prompt": prompt, "size": "512x512"},
            timeout=20
        )
        if response.status_code == 200:
            data = response.json()
            if data.get("image"):
                image_data = base64.b64decode(data["image"])
                return save_image_bytes(image_data, topic)
    except Exception as e:
        logger.error(f"‚ùå QuickAI error: {e}")
    return None

def try_proxyfusion(prompt, topic):
    """ProxyFusion API"""
    try:
        logger.info("üé® ProxyFusion –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        response = requests.post(
            "https://api.proxyfusion.ai/generate",
            json={"prompt": prompt, "width": 512, "height": 512},
            timeout=20
        )
        if response.status_code == 200:
            data = response.json()
            if data.get("image_url"):
                return save_image_from_url(data["image_url"], topic)
    except Exception as e:
        logger.error(f"‚ùå ProxyFusion error: {e}")
    return None

def try_openart(prompt, topic):
    """OpenArt API"""
    try:
        logger.info("üé® OpenArt –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        response = requests.post(
            "https://api.openart.ai/v1/generate",
            json={"prompt": prompt, "width": 512, "height": 512},
            timeout=20
        )
        if response.status_code == 200:
            data = response.json()
            if data.get("image_url"):
                return save_image_from_url(data["image_url"], topic)
    except Exception as e:
        logger.error(f"‚ùå OpenArt error: {e}")
    return None

def try_local_sd(prompt, topic):
    """–õ–æ–∫–∞–ª—å–Ω–∞—è Stable Diffusion —á–µ—Ä–µ–∑ –ø—É–±–ª–∏—á–Ω—ã–µ API"""
    try:
        logger.info("üé® –õ–æ–∫–∞–ª—å–Ω–∞—è SD –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        # –ü—É–±–ª–∏—á–Ω—ã–µ Stable Diffusion API
        endpoints = [
            "https://stablediffusionapi.com/api/v3/text2img",
            "https://api.stability.ai/v1/generation/stable-diffusion-512-v2-1/text-to-image"
        ]
        
        for endpoint in endpoints:
            try:
                response = requests.post(
                    endpoint,
                    json={"prompt": prompt, "width": 512, "height": 512},
                    timeout=25
                )
                if response.status_code == 200:
                    data = response.json()
                    if data.get("output"):
                        return save_image_from_url(data["output"][0], topic)
                    elif data.get("artifacts"):
                        image_data = base64.b64decode(data["artifacts"][0]["base64"])
                        return save_image_bytes(image_data, topic)
            except:
                continue
    except Exception as e:
        logger.error(f"‚ùå Local SD error: {e}")
    return None

def try_stability_public(prompt, topic):
    """Stability AI –ø—É–±–ª–∏—á–Ω—ã–π –¥–æ—Å—Ç—É–ø"""
    try:
        logger.info("üé® Stability AI –≥–µ–Ω–µ—Ä–∞—Ü–∏—è...")
        response = requests.post(
            "https://api.stability.ai/v1/generation/stable-diffusion-v1-5/text-to-image",
            headers={"Authorization": "Bearer sk-public-demo"},  # –ü—É–±–ª–∏—á–Ω—ã–π –¥–µ–º–æ-–∫–ª—é—á
            json={
                "text_prompts": [{"text": prompt}],
                "cfg_scale": 7,
                "height": 512,
                "width": 512,
                "samples": 1,
                "steps": 30
            },
            timeout=25
        )
        if response.status_code == 200:
            data = response.json()
            if data.get("artifacts"):
                image_data = base64.b64decode(data["artifacts"][0]["base64"])
                return save_image_bytes(image_data, topic)
    except Exception as e:
        logger.error(f"‚ùå Stability AI error: {e}")
    return None

def save_image_bytes(image_data, topic):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ bytes"""
    try:
        os.makedirs("assets/images/posts", exist_ok=True)
        filename = f"assets/images/posts/{generate_slug(topic)}.png"
        
        with open(filename, "wb") as f:
            f.write(image_data)
        
        logger.info(f"üíæ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filename}")
        return filename
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")
        return None

def save_image_from_url(url, topic):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ URL"""
    try:
        logger.info(f"üì• –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ URL: {url[:80]}...")
        response = requests.get(url, timeout=30)
        if response.status_code == 200:
            return save_image_bytes(response.content, topic)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ URL: {e}")
    return None

def generate_enhanced_placeholder(topic):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π placeholder —Å AI-—Å—Ç–∏–ª–µ–º"""
    try:
        os.makedirs("assets/images/posts", exist_ok=True)
        filename = f"assets/images/posts/{generate_slug(topic)}.png"
        width, height = 800, 400
        
        # –°–æ–∑–¥–∞–µ–º —Ñ—É—Ç—É—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π —Ñ–æ–Ω
        img = Image.new('RGB', (width, height), color='#0f172a')
        draw = ImageDraw.Draw(img)
        
        # –°–æ–∑–¥–∞–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Ñ–æ–Ω —Å AI-—Å—Ç–∏–ª–µ–º
        for i in range(height):
            # –°–∏–Ω–µ-—Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π –≥—Ä–∞–¥–∏–µ–Ω—Ç
            r = int(15 + (i/height)*40)
            g = int(23 + (i/height)*60)
            b = int(42 + (i/height)*100)
            draw.line([(0, i), (width, i)], fill=(r, g, b))
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–µ—Ç–∫—É (tech grid effect)
        for i in range(0, width, 40):
            draw.line([(i, 0), (i, height)], fill=(255, 255, 255, 25))
        for i in range(0, height, 40):
            draw.line([(0, i), (width, i)], fill=(255, 255, 255, 25))
        
        # –¢–µ–∫—Å—Ç
        wrapped_text = textwrap.fill(topic, width=35)
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —à—Ä–∏—Ñ—Ç—ã
        try:
            font = ImageFont.truetype("Arial.ttf", 22)
        except:
            try:
                font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 20)
            except:
                font = ImageFont.load_default()
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø–æ–∑–∏—Ü–∏—é —Ç–µ–∫—Å—Ç–∞
        bbox = draw.textbbox((0, 0), wrapped_text, font=font)
        text_width = bbox[2] - bbox[0]
        text_height = bbox[3] - bbox[1]
        
        x = (width - text_width) / 2
        y = (height - text_height) / 2
        
        # –¢–µ–Ω—å —Ç–µ–∫—Å—Ç–∞
        draw.text((x+3, y+3), wrapped_text, font=font, fill="#000000")
        # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç
        draw.text((x, y), wrapped_text, font=font, fill="#ffffff")
        
        # –î–æ–±–∞–≤–ª—è–µ–º AI badge
        draw.rectangle([(10, height-35), (120, height-10)], fill="#6366f1")
        draw.text((15, height-30), "AI 
