# .github/scripts/generate_content.py
import requests
import os
import time
import argparse
from PIL import Image
import io

def generate_with_huggingface(prompt):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Hugging Face API
    –ë–µ—Å–ø–ª–∞—Ç–Ω–æ: 30k —Ç–æ–∫–µ–Ω–æ–≤ –≤ –º–µ—Å—è—Ü (~100+ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)
    """
    try:
        HF_TOKEN = os.getenv('HF_API_TOKEN')
        if not HF_TOKEN:
            raise ValueError("HF_API_TOKEN not found")
        
        # üîß –£–ª—É—á—à–∞–µ–º –ø—Ä–æ–º–ø—Ç
        enhanced_prompt = f"{prompt}, digital art, futuristic, professional, 4k, ultra detailed, high quality"
        
        print(f"üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é —á–µ—Ä–µ–∑ Hugging Face: {enhanced_prompt}")
        
        API_URL = "https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5"
        headers = {"Authorization": f"Bearer {HF_TOKEN}"}
        
        payload = {
            "inputs": enhanced_prompt,
            "parameters": {
                "width": 1024,
                "height": 512,
                "num_inference_steps": 25,
                "guidance_scale": 7.5
            }
        }
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        response = requests.post(API_URL, headers=headers, json=payload)
        response.raise_for_status()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        filename = f"hf_{int(time.time())}.png"
        filepath = f"static/images/posts/{filename}"
        
        with open(filepath, "wb") as f:
            f.write(response.content)
        
        print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {filepath}")
        return filepath
        
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 503:
            print("‚è≥ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, –∂–¥—É 30 —Å–µ–∫—É–Ω–¥...")
            time.sleep(30)
            return generate_with_huggingface(prompt)  # Retry
        else:
            print(f"‚ùå HTTP Error: {e}")
            return None
    except Exception as e:
        print(f"‚ùå Hugging Face error: {e}")
        return None

def generate_with_replicate(prompt):
    """Fallback: Replicate.com (~$0.01 –∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)"""
    try:
        print("üîÑ –ü—Ä–æ–±—É—é Replicate –∫–∞–∫ fallback...")
        
        # Replicate API (–Ω—É–∂–µ–Ω REPLICATE_API_TOKEN)
        API_TOKEN = os.getenv('REPLICATE_API_TOKEN')
        if not API_TOKEN:
            return None
            
        response = requests.post(
            "https://api.replicate.com/v1/predictions",
            headers={
                "Authorization": f"Token {API_TOKEN}",
                "Content-Type": "application/json"
            },
            json={
                "version": "ac732df83cea7fff18b8472768c88ad041fa750ff7682a21affe81863cbe77e4",
                "input": {
                    "prompt": f"{prompt}, digital art, professional",
                    "width": 1024,
                    "height": 512
                }
            }
        )
        
        # ... (–∫–æ–¥ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞ Replicate)
        
    except:
        return None

def main():
    parser = argparse.ArgumentParser(description='AI Content Generator')
    parser.add_argument('--count', type=int, default=1, help='Number of articles')
    parser.add_argument('--debug', action='store_true', help='Debug mode')
    
    args = parser.parse_args()
    
    print("üîÑ Starting content generation...")
    print(f"üìä Articles to generate: {args.count}")
    
    # –ü—Ä–∏–º–µ—Ä –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    test_prompt = "AI technology futuristic background"
    image_path = generate_with_huggingface(test_prompt)
    
    if image_path:
        print(f"‚úÖ Success! Image: {image_path}")
    else:
        print("‚ùå Image generation failed")
    
    # –ó–¥–µ—Å—å –≤–∞—à–∞ –æ—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç–µ–π
    print("‚úÖ Content generation completed!")

if __name__ == "__main__":
    main()
