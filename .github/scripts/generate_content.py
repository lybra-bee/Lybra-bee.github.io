#!/usr/bin/env python3
import os
import json
import requests
import random
from datetime import datetime, timezone
import glob
import base64
import time
import re

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–ª—é—á–µ–π ---
HF_TOKEN = "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"
DEEP_AI_KEY = "98c841c4"

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–º—ã —Å—Ç–∞—Ç—å–∏ ---
def generate_ai_trend_topic():
    current_trends_2025 = [
        "Multimodal AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞—É–¥–∏–æ –≤ –µ–¥–∏–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö",
        "AI –∞–≥–µ–Ω—Ç—ã –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å–ø–æ—Å–æ–±–Ω—ã–µ –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏",
        "–ö–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ä—ã–≤ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
        "–ù–µ–π—Ä–æ–º–æ—Ä—Ñ–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–Ω–µ—Ä–≥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π",
        "Generative AI —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫–æ–¥–∞ –∏ –¥–∏–∑–∞–π–Ω–æ–≤ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º",
        "Edge AI –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –±–µ–∑ –æ–±–ª–∞—á–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏",
        "AI –¥–ª—è –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç —É–≥—Ä–æ–∑",
        "–≠—Ç–∏—á–Ω—ã–π AI –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
        "AI –≤ healthcare –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ª–µ–∫–∞—Ä—Å—Ç–≤ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω–∞",
        "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞",
        "AI –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∂–∞—Ç–∏–µ –º–æ–¥–µ–ª–µ–π –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ inference",
        "–î–æ–≤–µ—Ä–µ–Ω–Ω—ã–π AI –æ–±—ä—è—Å–Ω–∏–º—ã–µ –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã",
        "AI –¥–ª—è –∫–ª–∏–º–∞—Ç–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –∏ —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è",
        "–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–∏—Ñ—Ä–æ–≤—ã–µ –ø–æ–º–æ—â–Ω–∏–∫–∏",
        "AI –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—á–µ–±–Ω—ã–µ –ø–ª–∞–Ω—ã"
    ]
    application_domains = [
        "–≤ –≤–µ–± —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏ cloud native –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö",
        "–≤ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∏ IoT —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–∞—Ö –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –∞–Ω–∞–ª–∏–∑–µ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –±–∏–∑–Ω–µ—Å –∞–Ω–∞–ª–∏—Ç–∏–∫–µ",
        "–≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –∫–∏–±–µ—Ä–∑–∞—â–∏—Ç–µ",
        "–≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –∏ –±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö",
        "–≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ —Ñ–∏–Ω—Ç–µ—Ö–µ",
        "–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ smart city –∏ —É–º–Ω–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ",
        "–≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ EdTech"
    ]
    trend = random.choice(current_trends_2025)
    domain = random.choice(application_domains)
    topic_formats = [
        f"{trend} {domain} –≤ 2025 –≥–æ–¥—É",
        f"–¢–µ–Ω–¥–µ–Ω—Ü–∏–∏ 2025 {trend} {domain}",
        f"{trend} —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è {domain} –≤ 2025",
        f"–ö–∞–∫ {trend} —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç {domain} –≤ 2025 –≥–æ–¥—É",
        f"–ò–Ω–Ω–æ–≤–∞—Ü–∏–∏ 2025 {trend} –¥–ª—è {domain}",
        f"{trend} –±—É–¥—É—â–µ–µ {domain} –≤ 2025 –≥–æ–¥—É",
        f"–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ {trend} –≤ {domain} 2025"
    ]
    return random.choice(topic_formats)

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è slug ---
def generate_slug(text):
    text = text.lower()
    text = text.replace(' ', '-')
    text = text.replace('--', '-')
    text = re.sub(r'[^a-z0-9\-]', '', text)
    text = re.sub(r'-+', '-', text)
    text = text.strip('-')
    return text[:60]

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è frontmatter ---
def generate_frontmatter(title, content, model_used, image_url):
    now = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
    escaped_title = title.replace(':', ' -').replace('"', '').replace("'", "").replace('\\', '')
    frontmatter_lines = [
        "---",
        f'title: "{escaped_title}"',
        f"date: {now}",
        "draft: false",
        'tags: ["AI", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "2025"]',
        'categories: ["–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"]',
        'summary: "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –æ–± –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ"'
    ]
    if image_url:
        frontmatter_lines.append(f'image: "{image_url}"')
    frontmatter_lines.append("---")
    frontmatter_lines.append(content)
    return "\n".join(frontmatter_lines)

# --- –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å—Ç–∞—Ç–µ–π ---
def clean_old_articles(keep_last=3):
    print(f"üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å—Ç–∞—Ç–µ–π, –æ—Å—Ç–∞–≤–ª—è–µ–º {keep_last} –ø–æ—Å–ª–µ–¥–Ω–∏—Ö...")
    try:
        articles = glob.glob("content/posts/*.md")
        if not articles:
            print("üìÅ –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ—á–∏—Å—Ç–∫–∏")
            return
        articles.sort(key=os.path.getmtime, reverse=True)
        articles_to_keep = articles[:keep_last]
        articles_to_delete = articles[keep_last:]
        for article_path in articles_to_delete:
            try:
                os.remove(article_path)
                slug = os.path.basename(article_path).replace('.md', '')
                image_path = f"assets/images/posts/{slug}.png"
                if os.path.exists(image_path):
                    os.remove(image_path)
            except:
                pass
    except:
        pass

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Hugging Face ---
def generate_image_huggingface(topic, hf_token):
    print("üîÑ –ü—Ä–æ–±—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä: HuggingFace")
    url = "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0"
    headers = {"Authorization": f"Bearer {hf_token}", "Content-Type": "application/json"}
    prompts = [
        f"Futuristic digital illustration for article about {topic}. Clean, professional, neon colors, AI, data visualization, technology theme, no text",
        f"Cyberpunk concept art for {topic}. Neural networks, glowing holographic interfaces, futuristic city, cinematic lighting",
        f"Abstract high-tech illustration for {topic}. Geometric shapes, digital particles, circuits, futuristic style",
        f"Modern AI concept for {topic}. Digital brain, quantum computing elements, sci-fi environment, vibrant colors",
        f"Creative tech visualization for {topic}. Minimalist, professional, glowing effects, digital art style"
    ]
    payload = {"inputs": random.choice(prompts), "options":{"wait_for_model":True}}
    try:
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        if response.status_code == 200:
            data = response.json()
            if isinstance(data, dict) and "images" in data:
                image_bytes = base64.b64decode(data["images"][0])
                os.makedirs("assets/images/posts", exist_ok=True)
                slug = generate_slug(topic)
                filename = f"posts/{slug}.png"
                full_path = f"assets/images/{filename}"
                with open(full_path,"wb") as f: f.write(image_bytes)
                print(f"‚úÖ Hugging Face: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ: {filename}")
                return f"/images/{filename}"
        print(f"‚ö†Ô∏è Hugging Face –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {response.status_code}")
    except Exception as e:
        print(f"‚ùå Hugging Face –æ—à–∏–±–∫–∞: {e}")
    return None

# --- –î—Ä—É–≥–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã ---
def generate_image_deepai(topic):
    print("üîÑ –ü—Ä–æ–±—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä: DeepAI")
    try:
        response = requests.post(
            "https://api.deepai.org/api/text2img",
            data={"text": topic},
            headers={"Api-Key": DEEP_AI_KEY},
            timeout=60
        )
        if response.status_code == 200:
            data = response.json()
            if "output_url" in data:
                print("‚úÖ DeepAI —É—Å–ø–µ—à–Ω–æ")
                return data["output_url"]
    except:
        pass
    print("‚ö†Ô∏è DeepAI –≤–µ—Ä–Ω—É–ª None")
    return None

def generate_image_craiyon(topic):
    print("üîÑ –ü—Ä–æ–±—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä: Craiyon")
    try:
        response = requests.post(
            "https://backend.craiyon.com/generate",
            json={"prompt": topic},
            timeout=60
        )
        if response.status_code == 200:
            data = response.json()
            if "images" in data and data["images"]:
                print("‚úÖ Craiyon —É—Å–ø–µ—à–Ω–æ")
                return data["images"][0]
    except:
        pass
    print("‚ö†Ô∏è Craiyon –≤–µ—Ä–Ω—É–ª None")
    return None

def generate_image_lexica(topic):
    print("üîÑ –ü—Ä–æ–±—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä: Lexica")
    try:
        # –ó–∞–≥–ª—É—à–∫–∞, —Ç–∞–∫ –∫–∞–∫ Lexica –ø—É–±–ª–∏—á–Ω–æ–≥–æ API –Ω–µ—Ç
        return None
    except:
        return None

def generate_image_artbreeder(topic):
    print("üîÑ –ü—Ä–æ–±—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä: Artbreeder")
    try:
        # –ó–∞–≥–ª—É—à–∫–∞, –º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å —á–µ—Ä–µ–∑ web scraping –∏–ª–∏ –∏—Ö API –µ—Å–ª–∏ –µ—Å—Ç—å
        return f"https://placehold.co/1024x1024?text=AI+{topic}"
    except:
        return None

# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ---
def generate_article_image(topic):
    generators = [
        lambda: generate_image_huggingface(topic, HF_TOKEN),
        lambda: generate_image_deepai(topic),
        lambda: generate_image_craiyon(topic),
        lambda: generate_image_lexica(topic),
        lambda: generate_image_artbreeder(topic)
    ]
    for gen in generators:
        img = gen()
        if img:
            return img
    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∏ –æ–¥–Ω–∏–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–º")
    return None

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ OpenRouter/Groq ---
def generate_article_content(topic):
    # –ó–¥–µ—Å—å –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –±—ã–ª–æ: OpenRouter –≤ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–µ, Groq –∑–∞–ø–∞—Å–Ω–æ–π
    openrouter_key = os.getenv('OPENROUTER_API_KEY')
    groq_key = os.getenv('GROQ_API_KEY')
    models_to_try = []

    if openrouter_key:
        openrouter_models = [
            "anthropic/claude-3-haiku",
            "google/gemini-pro",
            "mistralai/mistral-7b-instruct",
            "meta-llama/llama-3-8b-instruct"
        ]
        for model_name in openrouter_models:
            models_to_try.append((model_name, lambda m=model_name: generate_with_openrouter(openrouter_key, m, topic)))

    if groq_key:
        groq_models = [
            "llama-3.1-8b-instant",
            "llama-3.2-1b-preview",
            "llama-3.2-3b-preview",
            "mixtral-8x7b-32768",
            "gemma2-9b-it"
        ]
        for model_name in groq_models:
            models_to_try.append((f"Groq-{model_name}", lambda m=model_name: generate_with_groq(groq_key, m, topic)))

    for model_name, generate_func in models_to_try:
        try:
            print(f"üîÑ –ü—Ä–æ–±—É–µ–º: {model_name}")
            result = generate_func()
            if result and len(result.strip()) > 100:
                print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —á–µ—Ä–µ–∑ {model_name}")
                return result, model_name
            time.sleep(1)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ {model_name}: {str(e)[:100]}")
            continue

    fallback_content = f"""# {topic}

## –í–≤–µ–¥–µ–Ω–∏–µ
{topic} - —ç—Ç–æ –≤–∞–∂–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤ —Ä–∞–∑–≤–∏—Ç–∏–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –Ω–∞ 2025 –≥–æ–¥.

## –û—Å–Ω–æ–≤–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã
- **–¢–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏**: {topic} –≤–∫–ª—é—á–∞–µ—Ç –ø–µ—Ä–µ–¥–æ–≤—ã–µ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ AI
- **–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ**: –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è –Ω–∞—Ö–æ–¥–∏—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ—Ç—Ä–∞—Å–ª—è—Ö
- **–ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã —Ä–∞–∑–≤–∏—Ç–∏—è**: –û–∂–∏–¥–∞–µ—Ç—Å—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π —Ä–æ—Å—Ç –≤ –±–ª–∏–∂–∞–π—à–∏–µ –≥–æ–¥—ã

## –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –¥–µ—Ç–∞–ª–∏
–ú–æ–¥–µ–ª–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è {topic} –∏—Å–ø–æ–ª—å–∑—É—é—Ç —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π.

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
{topic} –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –∫–ª—é—á–µ–≤–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞–∑–≤–∏—Ç–∏—è –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.
"""
    return fallback_content, "fallback-generator"

# –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ OpenRouter/Groq
def generate_with_openrouter(api_key, model_name, topic): return f"–°—Ç–∞—Ç—å—è –ø–æ —Ç–µ–º–µ {topic}", model_name
def generate_with_groq(api_key, model_name, topic): return f"–°—Ç–∞—Ç—å—è –ø–æ —Ç–µ–º–µ {topic}", model_name

# --- –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ---
def generate_content():
    print("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
    KEEP_LAST_ARTICLES = 3
    clean_old_articles(KEEP_LAST_ARTICLES)
    selected_topic = generate_ai_trend_topic()
    print(f"üìù –ê–∫—Ç—É–∞–ª—å–Ω–∞—è —Ç–µ–º–∞ 2025: {selected_topic}")

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image_filename = generate_article_image(selected_topic)

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏
    content, model_used = generate_article_content(selected_topic)

    # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
    date = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    slug = generate_slug(selected_topic)
    filename = f"content/posts/{date}-{slug}.md"
    frontmatter = generate_frontmatter(selected_topic, content, model_used, image_filename)
    os.makedirs("content/posts", exist_ok=True)
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(frontmatter)

    print(f"‚úÖ –°—Ç–∞—Ç—å—è —Å–æ–∑–¥–∞–Ω–∞: {filename}")
    return filename

if __name__ == "__main__":
    generate_content()
