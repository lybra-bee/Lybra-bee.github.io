#!/usr/bin/env python3
import os
import json
import requests
import random
from datetime import datetime
import glob
import base64
import time
import urllib.parse
import subprocess

def generate_ai_trend_topic():
    current_trends_2025 = [
        "Multimodal AI - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞—É–¥–∏–æ –≤ –µ–¥–∏–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö",
        "AI –∞–≥–µ–Ω—Ç—ã - –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å–ø–æ—Å–æ–±–Ω—ã–µ –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏",
        "–ö–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ - –ø—Ä–æ—Ä—ã–≤ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
        "–ù–µ–π—Ä–æ–º–æ—Ä—Ñ–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è - —ç–Ω–µ—Ä–≥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π",
        "Generative AI - —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞, –∫–æ–¥–∞ –∏ –¥–∏–∑–∞–π–Ω–æ–≤ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º",
        "Edge AI - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –±–µ–∑ –æ–±–ª–∞—á–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏",
        "AI –¥–ª—è –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ - –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç —É–≥—Ä–æ–∑",
        "–≠—Ç–∏—á–Ω—ã–π AI - –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
        "AI –≤ healthcare - –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞, —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ª–µ–∫–∞—Ä—Å—Ç–≤ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω–∞",
        "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã - –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞",
        "AI –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è - —Å–∂–∞—Ç–∏–µ –º–æ–¥–µ–ª–µ–π –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ inference",
        "–î–æ–≤–µ—Ä–µ–Ω–Ω—ã–π AI - –æ–±—ä—è—Å–Ω–∏–º—ã–µ –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã",
        "AI –¥–ª—è –∫–ª–∏–º–∞—Ç–∞ - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –∏ —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è",
        "–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã - –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–∏—Ñ—Ä–æ–≤—ã–µ –ø–æ–º–æ—â–Ω–∏–∫–∏",
        "AI –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ - –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—á–µ–±–Ω—ã–µ –ø–ª–∞–Ω—ã"
    ]
    
    application_domains = [
        "–≤ –≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏ cloud-native –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö",
        "–≤ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∏ IoT —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–∞—Ö –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –∞–Ω–∞–ª–∏–∑–µ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫–µ",
        "–≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –∫–∏–±–µ—Ä–∑–∞—â–∏—Ç–µ",
        "–≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –∏ –±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö",
        "–≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ —Ñ–∏–Ω—Ç–µ—Ö–µ",
        "–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ smart city –∏ —É–º–Ω–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ",
        "–≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ EdTech"
    ]
    
    trend = random.choice(current_trends_2025)
    domain = random.choice(application_domains)
    
    topic_formats = [
        f"{trend} {domain} –≤ 2025 –≥–æ–¥—É",
        f"–¢–µ–Ω–¥–µ–Ω—Ü–∏–∏ 2025: {trend} {domain}",
        f"{trend} - —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è {domain} –≤ 2025",
        f"–ö–∞–∫ {trend} —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç {domain} –≤ 2025 –≥–æ–¥—É",
        f"–ò–Ω–Ω–æ–≤–∞—Ü–∏–∏ 2025: {trend} –¥–ª—è {domain}",
        f"{trend} - –±—É–¥—É—â–µ–µ {domain} –≤ 2025 –≥–æ–¥—É",
        f"–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ {trend} –≤ {domain} 2025"
    ]
    
    return random.choice(topic_formats)

def generate_content():
    print("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
    
    KEEP_LAST_ARTICLES = 3
    clean_old_articles(KEEP_LAST_ARTICLES)
    
    selected_topic = generate_ai_trend_topic()
    print(f"üìù –ê–∫—Ç—É–∞–ª—å–Ω–∞—è —Ç–µ–º–∞ 2025: {selected_topic}")
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image_filename = generate_article_image(selected_topic)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
    content, model_used = generate_article_content(selected_topic)
    
    # –°–æ–∑–¥–∞—ë–º Markdown
    date = datetime.now().strftime("%Y-%m-%d")
    slug = generate_slug(selected_topic)
    filename = f"content/posts/{date}-{slug}.md"
    
    frontmatter = generate_frontmatter(selected_topic, content, model_used, image_filename)
    
    os.makedirs("content/posts", exist_ok=True)
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(frontmatter)
    
    print(f"‚úÖ –°—Ç–∞—Ç—å—è —Å–æ–∑–¥–∞–Ω–∞: {filename}")
    return filename

def generate_article_content(topic):
    openrouter_key = os.getenv('OPENROUTER_API_KEY')
    groq_key = os.getenv('GROQ_API_KEY')
    
    models_to_try = []
    
    if groq_key:
        groq_models = ["llama-3.1-8b-instant"]
        for model_name in groq_models:
            models_to_try.append((f"Groq-{model_name}", lambda m=model_name: generate_with_groq(groq_key, m, topic)))
    
    if openrouter_key:
        openrouter_models = ["anthropic/claude-3-haiku"]
        for model_name in openrouter_models:
            models_to_try.append((model_name, lambda m=model_name: generate_with_openrouter(openrouter_key, m, topic)))
    
    for model_name, generate_func in models_to_try:
        try:
            print(f"üîÑ –ü—Ä–æ–±—É–µ–º: {model_name}")
            result = generate_func()
            if result and len(result.strip()) > 100:
                print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —á–µ—Ä–µ–∑ {model_name}")
                return result, model_name
            time.sleep(1)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ {model_name}: {str(e)[:100]}")
            continue
    
    fallback_content = f"# {topic}\n\n–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Å—Ç–∞—Ç—å—è –æ {topic}."
    return fallback_content, "fallback-generator"

def generate_with_groq(api_key, model_name, topic):
    prompt = f"–ù–∞–ø–∏—à–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É: {topic}"
    response = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers={"Content-Type": "application/json","Authorization": f"Bearer {api_key}"},
        json={"model": model_name,"messages":[{"role":"user","content":prompt}],"max_tokens":1500,"temperature":0.7},
        timeout=30
    )
    if response.status_code == 200:
        data = response.json()
        if data.get('choices'):
            return data['choices'][0]['message']['content'].strip()
    raise Exception(f"HTTP {response.status_code}: {response.text[:200]}")

def generate_with_openrouter(api_key, model_name, topic):
    prompt = f"–ù–∞–ø–∏—à–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É: {topic}"
    response = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers={"Content-Type": "application/json","Authorization": f"Bearer {api_key}"},
        json={"model": model_name,"messages":[{"role":"user","content":prompt}],"max_tokens":1500,"temperature":0.7},
        timeout=30
    )
    if response.status_code == 200:
        data = response.json()
        if data.get('choices'):
            return data['choices'][0]['message']['content'].strip()
    raise Exception(f"HTTP {response.status_code}")

def generate_article_image(topic):
    print("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    groq_key = os.getenv('GROQ_API_KEY')
    stability_key = os.getenv('STABILITYAI_KEY')
    
    # –°–Ω–∞—á–∞–ª–∞ Groq
    if groq_key:
        try:
            prompt = f"Create tech image prompt for article: {topic}"
            response = requests.post(
                "https://api.groq.com/openai/v1/chat/completions",
                headers={"Content-Type": "application/json","Authorization": f"Bearer {groq_key}"},
                json={"model":"llama-3.1-8b-instant","messages":[{"role":"user","content":prompt}],"max_tokens":50},
                timeout=15
            )
            if response.status_code==200:
                data=response.json()
                img_prompt=data['choices'][0]['message']['content'].strip()
                filename=try_stability_ai(img_prompt, topic)
                if filename:
                    return filename
        except Exception as e:
            print(f"‚ö†Ô∏è Groq image prompt error: {e}")
    
    # Stability AI fallback
    if stability_key:
        filename = try_stability_ai(f"Tech futuristic image: {topic}", topic)
        if filename:
            return filename
    
    print("‚ÑπÔ∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
    return None

def try_stability_ai(prompt, topic):
    stability_key = os.getenv('STABILITYAI_KEY')
    if not stability_key:
        return None
    url="https://api.stability.ai/v1/generation/stable-diffusion-xl-1024-v1-0/text-to-image"
    headers={"Authorization": f"Bearer {stability_key}","Content-Type":"application/json"}
    payload={"text_prompts":[{"text":prompt}],"cfg_scale":7,"height":512,"width":512,"samples":1,"steps":20}
    response = requests.post(url, headers=headers, json=payload, timeout=30)
    if response.status_code==200:
        data=response.json()
        if 'artifacts' in data and data['artifacts']:
            img_data=base64.b64decode(data['artifacts'][0]['base64'])
            return save_article_image(img_data, topic)
    return None

def save_article_image(image_data, topic):
    try:
        os.makedirs("static/images/posts", exist_ok=True)
        slug = generate_slug(topic)
        filename=f"posts/{slug}.jpg"
        full_path=f"static/images/{filename}"
        with open(full_path,'wb') as f:
            f.write(image_data)
        return f"/images/{filename}"
    except:
        return None

def clean_old_articles(keep_last=3):
    articles=glob.glob("content/posts/*.md")
    articles.sort(key=os.path.getmtime, reverse=True)
    for article in articles[keep_last:]:
        os.remove(article)
        slug=os.path.basename(article).replace(".md","")
        img_path=f"static/images/posts/{slug}.jpg"
        if os.path.exists(img_path):
            os.remove(img_path)

def generate_slug(topic):
    slug = topic.lower()
    for ch in [' ',':','(',')','/','\\','.',',','--']:
        slug=slug.replace(ch,'-')
    slug=''.join(c for c in slug if c.isalnum() or c=='-')
    while '--' in slug:
        slug=slug.replace('--','-')
    return slug[:50]

def generate_frontmatter(topic, content, model_used, image_filename=None):
    frontmatter=f"---\ntitle: \"{topic}\"\ndate: {datetime.now().strftime('%Y-%m-%d')}\nmodel: {model_used}\n"
    if image_filename:
        frontmatter+=f"image: \"{image_filename}\"\n"
    frontmatter+="---\n\n"
    frontmatter+=content
    return frontmatter

if __name__=="__main__":
    filename = generate_content()
    print("üì¶ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞, –∑–∞–ø—É—Å–∫–∞–µ–º Hugo...")
    subprocess.run(["hugo", "--minify"])
