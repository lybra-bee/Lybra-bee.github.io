import requests
import os
import time
import argparse
import json
import random
from datetime import datetime, timedelta
import feedparser
from PIL import Image
import io

def get_trending_topics():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ç–µ–º –∏–∑ RSS –∏ –Ω–æ–≤–æ—Å—Ç–µ–π"""
    try:
        topics = []
        
        # RSS –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Ç–µ–º
        rss_feeds = [
            "https://habr.com/ru/rss/articles/?fl=ru",
            "https://news.ycombinator.com/rss",
            "https://www.reddit.com/r/MachineLearning/.rss"
        ]
        
        for feed_url in rss_feeds:
            try:
                feed = feedparser.parse(feed_url)
                for entry in feed.entries[:10]:
                    if 'title' in entry:
                        topics.append(entry.title)
                        if 'summary' in entry:
                            topics.append(entry.summary[:100])
            except:
                continue
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç–µ–º—ã –ø–æ AI
        current_trends = [
            "–ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ GPT-5 –∏ –ò–ò –±—É–¥—É—â–µ–≥–æ",
            "–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ò–ò –≤ –±–∏–∑–Ω–µ—Å–µ 2024",
            "–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
            "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –≤ –≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ",
            "–ò–ò –∏ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å: –Ω–æ–≤—ã–µ –≤—ã–∑–æ–≤—ã",
            "–≠—Ç–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
            "–ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å –ø–æ–º–æ—â—å—é —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π",
            "–ö–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–µ –∑—Ä–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
            "–ò–ò –≤ –º–µ–¥–∏—Ü–∏–Ω–µ –∏ –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏",
            "–ë—É–¥—É—â–µ–µ —Ä–∞–±–æ—Ç—ã –≤ —ç–ø–æ—Ö—É –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
            "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –≤–∏–¥–µ–æ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π",
            "–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã 2024",
            "–ö–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
            "–ò–ò –¥–ª—è –∫–ª–∏–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π –∏ —ç–∫–æ–ª–æ–≥–∏–∏",
            "–ù–µ–π—Ä–æ–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –∏ brain-computer interfaces"
        ]
        
        topics.extend(current_trends)
        return list(set(topics))[:20]  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–æ–≤: {e}")
        return [
            "–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –≤ –≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ 2024",
            "–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –ò–ò –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞",
            "–ú–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –±–æ–ª—å—à–∏–µ –¥–∞–Ω–Ω—ã–µ",
            "–ù–µ–π—Ä–æ—Å–µ—Ç–∏ –≤ –±–∏–∑–Ω–µ—Å-–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏"
        ]

def generate_article(topic, api_type="groq"):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ Groq –∏–ª–∏ OpenRouter"""
    try:
        if api_type == "groq":
            api_key = os.getenv('GROQ_API_KEY')
            url = "https://api.groq.com/openai/v1/chat/completions"
            model = "llama-3.1-70b-versatile"
        else:
            api_key = os.getenv('OPENROUTER_API_KEY')
            url = "https://openrouter.ai/api/v1/chat/completions"
            model = "meta-llama/llama-3.1-70b"
        
        if not api_key:
            raise ValueError(f"{api_type.upper()}_API_KEY not found")
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        if api_type == "openrouter":
            headers.update({
                "HTTP-Referer": "https://github.com/lybra-bee/lybra-bee.github.io",
                "X-Title": "AI Content Generator"
            })
        
        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏
        system_prompt = """–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –ø–∏—Å–∞—Ç–µ–ª—å –∏ —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º—É –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É. 
–ü–∏—à–∏ –ø–æ–¥—Ä–æ–±–Ω—ã–µ, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ –∏ —Ö–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. 
–ò—Å–ø–æ–ª—å–∑—É–π –∑–∞–≥–æ–ª–æ–≤–∫–∏ H2, H3, —Å–ø–∏—Å–∫–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã. –°—Ç–∞—Ç—å—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω–æ–π –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω–æ–π."""

        payload = {
            "model": model,
            "messages": [
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user", 
                    "content": f"–ù–∞–ø–∏—à–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—É—é —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É: '{topic}'. –û–±—ä–µ–º: 1500-2000 —Å–ª–æ–≤. –í–∫–ª—é—á–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã, –∫–µ–π—Å—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∏ –±—É–¥—É—â–∏–µ —Ç—Ä–µ–Ω–¥—ã. –§–æ—Ä–º–∞—Ç: Markdown —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ ## –∏ ###."
                }
            ],
            "max_tokens": 4000,
            "temperature": 0.7,
            "top_p": 0.9
        }
        
        print(f"üìù –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Å—Ç–∞—Ç—å—é —á–µ—Ä–µ–∑ {api_type.upper()}: {topic}")
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        
        content = response.json()['choices'][0]['message']['content']
        print(f"‚úÖ –°—Ç–∞—Ç—å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞! –î–ª–∏–Ω–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        return content
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏ ({api_type}): {e}")
        return None

def generate_image(prompt, retry_count=0):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Hugging Face —Å fallback"""
    try:
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º Hugging Face
        HF_TOKEN = os.getenv('HF_API_TOKEN')
        if HF_TOKEN and retry_count < 2:
            try:
                print(f"üé® –ü—Ä–æ–±—É—é Hugging Face: {prompt}")
                
                API_URL = "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0"
                headers = {"Authorization": f"Bearer {HF_TOKEN}"}
                
                payload = {
                    "inputs": f"{prompt}, digital art, futuristic, professional, 4k, ultra detailed, high quality",
                    "parameters": {
                        "width": 1024,
                        "height": 512,
                        "num_inference_steps": 25,
                        "guidance_scale": 7.5
                    }
                }
                
                response = requests.post(API_URL, headers=headers, json=payload, timeout=60)
                
                if response.status_code == 200:
                    filename = f"image_{int(time.time())}.png"
                    filepath = f"static/images/posts/{filename}"
                    
                    with open(filepath, "wb") as f:
                        f.write(response.content)
                    
                    print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ: {filepath}")
                    return filepath
                else:
                    print(f"‚ö†Ô∏è HF –≤–µ—Ä–Ω—É–ª {response.status_code}, –ø—Ä–æ–±—É—é fallback...")
            except:
                pass
        
        # Fallback: Replicate
        REPLICATE_TOKEN = os.getenv('REPLICATE_API_TOKEN')
        if REPLICATE_TOKEN:
            try:
                print(f"üîÑ –ü—Ä–æ–±—É—é Replicate: {prompt}")
                
                response = requests.post(
                    "https://api.replicate.com/v1/predictions",
                    headers={
                        "Authorization": f"Token {REPLICATE_TOKEN}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "version": "ac732df83cea7fff18b8472768c88ad041fa750ff7682a21affe81863cbe77e4",
                        "input": {
                            "prompt": f"{prompt}, digital art, professional, 4k quality",
                            "width": 1024,
                            "height": 512,
                            "num_outputs": 1
                        }
                    },
                    timeout=60
                )
                
                if response.status_code == 200:
                    prediction_id = response.json()['id']
                    
                    # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                    for _ in range(10):
                        time.sleep(5)
                        status_response = requests.get(
                            f"https://api.replicate.com/v1/predictions/{prediction_id}",
                            headers={"Authorization": f"Token {REPLICATE_TOKEN}"}
                        )
                        
                        if status_response.json()['status'] == 'succeeded':
                            image_url = status_response.json()['output'][0]
                            img_data = requests.get(image_url).content
                            
                            filename = f"image_{int(time.time())}.png"
                            filepath = f"static/images/posts/{filename}"
                            
                            with open(filepath, "wb") as f:
                                f.write(img_data)
                            
                            print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ —á–µ—Ä–µ–∑ Replicate: {filepath}")
                            return filepath
                
            except:
                pass
        
        # Final fallback: Unsplash
        UNSPLASH_KEY = os.getenv('UNSPLASH_API_KEY')
        if UNSPLASH_KEY:
            try:
                print(f"üåÖ –ü—Ä–æ–±—É—é Unsplash: {prompt}")
                
                search_url = "https://api.unsplash.com/search/photos"
                headers = {"Authorization": f"Client-ID {UNSPLASH_KEY}"}
                
                search_response = requests.get(
                    search_url,
                    headers=headers,
                    params={"query": prompt, "per_page": 1},
                    timeout=30
                )
                
                if search_response.status_code == 200:
                    results = search_response.json()['results']
                    if results:
                        image_url = results[0]['urls']['regular']
                        img_data = requests.get(image_url).content
                        
                        filename = f"unsplash_{int(time.time())}.jpg"
                        filepath = f"static/images/posts/{filename}"
                        
                        with open(filepath, "wb") as f:
                            f.write(img_data)
                        
                        print(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å Unsplash: {filepath}")
                        return filepath
            except:
                pass
        
        return None
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        return None

def save_article(content, topic, image_path=None):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ —Å front matter"""
    try:
        import re
        from datetime import date
        
        # –°–æ–∑–¥–∞–µ–º SEO-–¥—Ä—É–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        clean_topic = re.sub(r'[^a-zA-Z0-9–∞-—è–ê-–Ø\s]', '', topic)
        filename = re.sub(r'\s+', '-', clean_topic.lower())[:50]
        
        today = date.today().strftime("%Y-%m-%d")
        full_filename = f"content/posts/{today}-{filename}.md"
        
        # Front matter –¥–ª—è Hugo
        front_matter = f"""---
title: "{topic}"
date: {today}
draft: false
description: "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –Ω–∞ —Ç–µ–º—É {topic}"
categories: ["–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"]
tags: ["ai", "–≥–µ–Ω–µ—Ä–∞—Ü–∏—è", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–Ω–µ–π—Ä–æ—Å–µ—Ç–∏"]
---
"""
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
        if image_path:
            image_filename = os.path.basename(image_path)
            front_matter = front_matter.replace('---', f'---\nimage: "/images/posts/{image_filename}"')
        
        full_content = front_matter + "\n" + content
        
        with open(full_filename, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        print(f"üíæ –°—Ç–∞—Ç—å—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {full_filename}")
        return full_filename
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—Ç–∞—Ç—å–∏: {e}")
        return None

def main():
    parser = argparse.ArgumentParser(description='AI Content Generator')
    parser.add_argument('--count', type=int, default=1, help='Number of articles')
    parser.add_argument('--debug', action='store_true', help='Debug mode')
    
    args = parser.parse_args()
    
    print("üîÑ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
    print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π: {args.count}")
    
    # –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç–µ–º—ã
    print("üì° –ü–æ–ª—É—á–∞—é –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç–µ–º—ã...")
    topics = get_trending_topics()
    selected_topics = random.sample(topics, min(args.count, len(topics)))
    
    generated_count = 0
    
    for i, topic in enumerate(selected_topics):
        print(f"\nüìñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {i+1}/{len(selected_topics)}: {topic}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç–∞—Ç—å—é
        content = generate_article(topic, "groq")
        if not content:
            content = generate_article(topic, "openrouter")
        
        if content:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_prompt = f"{topic}, digital art, futuristic style"
            image_path = generate_image(image_prompt)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ç—å—é
            article_path = save_article(content, topic, image_path)
            if article_path:
                generated_count += 1
        else:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç—å—é: {topic}")
    
    print(f"\n‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –£—Å–ø–µ—à–Ω–æ: {generated_count}/{len(selected_topics)}")

if __name__ == "__main__":
    main()
