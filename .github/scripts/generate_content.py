#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import requests
import random
from datetime import datetime, timezone
import glob
import base64
import time
import re
from pathlib import Path

# ====== –í–°–¢–†–û–ï–ù–ù–´–ï –ö–õ–Æ–ß–ò –î–õ–Ø –ë–ï–°–ü–õ–ê–¢–ù–´–• –ì–ï–ù–ï–†–ê–¢–û–†–û–í (–ü–û –ü–†–û–°–¨–ë–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø) ======
# Hugging Face ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º Inference API –¥–ª—è text-to-image
HF_TOKEN = "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"

# DeepAI ‚Äî –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç–∞—Ä–∏—Ñ (–º–æ–∂–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å—Å—è)
DEEPAI_API_KEY = "98c841c4"

# ====== –ù–ê–°–¢–†–û–ô–ö–ò ======
POSTS_DIR = Path("content/posts")
STATIC_IMG_DIR = Path("static/images/posts")
KEEP_LAST_ARTICLES = 3

# –ú–æ–¥–µ–ª–∏ Hugging Face –¥–ª—è text-to-image (–ø–µ—Ä–µ–±–æ—Ä –ø–æ –ø–æ—Ä—è–¥–∫—É)
HF_IMAGE_MODELS = [
    # –±—ã—Å—Ç—Ä—ã–µ/–ø–æ–ø—É–ª—è—Ä–Ω—ã–µ
    "stabilityai/sdxl-turbo",
    "runwayml/stable-diffusion-v1-5",
    "stabilityai/stable-diffusion-2-1",
    # –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
    "SG161222/Realistic_Vision_V5.1_noVAE",
]

def log(msg: str):
    print(msg, flush=True)

# ======================== –û–°–ù–û–í–ù–û–ô –ü–†–û–¶–ï–°–° ========================

def generate_content():
    log("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")

    # –ß–∏—Å—Ç–∏–º —Å—Ç–∞—Ä—ã–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ content/news (–±—ã–ª–∏ –±–∏—Ç—ã–µ YAML)
    cleanup_broken_news()

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ N –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å—Ç–∞—Ç–µ–π
    clean_old_articles(KEEP_LAST_ARTICLES)

    # –¢–µ–º–∞ –¥–Ω—è
    selected_topic = generate_ai_trend_topic()
    log(f"üìù –ê–∫—Ç—É–∞–ª—å–Ω–∞—è —Ç–µ–º–∞ 2025: {selected_topic}")

    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (—á—Ç–æ–±—ã —Å—Ä–∞–∑—É –∑–Ω–∞—Ç—å –ø—É—Ç—å)
    log("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
    image_url = generate_article_image(selected_topic)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ (OpenRouter -> Groq -> fallback)
    content_md, model_used = generate_article_content(selected_topic)

    # –°–æ–∑–¥–∞—ë–º —Ñ–∞–π–ª —Å—Ç–∞—Ç—å–∏
    date_prefix = datetime.now(timezone.utc).strftime("%Y-%m-%d")
    slug = generate_slug(selected_topic)
    filename = POSTS_DIR / f"{date_prefix}-{slug}.md"
    filename.parent.mkdir(parents=True, exist_ok=True)

    fm = generate_frontmatter(selected_topic, content_md, model_used, image_url)
    with open(filename, "w", encoding="utf-8") as f:
        f.write(fm)

    log(f"‚úÖ –°—Ç–∞—Ç—å—è —Å–æ–∑–¥–∞–Ω–∞: {filename}")
    return str(filename)


# ======================== –¢–ï–ú–ê –î–ù–Ø ========================

def generate_ai_trend_topic():
    current_trends_2025 = [
        "Multimodal AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞—É–¥–∏–æ –≤ –µ–¥–∏–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö",
        "AI –∞–≥–µ–Ω—Ç—ã –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã —Å–ø–æ—Å–æ–±–Ω—ã–µ –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∑–∞–¥–∞—á–∏",
        "–ö–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ä—ã–≤ –≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
        "–ù–µ–π—Ä–æ–º–æ—Ä—Ñ–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–Ω–µ—Ä–≥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π",
        "Generative AI —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∫–æ–¥–∞ –∏ –¥–∏–∑–∞–π–Ω–æ–≤ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º",
        "Edge AI –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ –±–µ–∑ –æ–±–ª–∞—á–Ω–æ–π –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏",
        "AI –¥–ª—è –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–∞—è –∑–∞—â–∏—Ç–∞ –æ—Ç —É–≥—Ä–æ–∑",
        "–≠—Ç–∏—á–Ω—ã–π AI –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
        "AI –≤ healthcare –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ª–µ–∫–∞—Ä—Å—Ç–≤ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω–∞",
        "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞",
        "AI –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∂–∞—Ç–∏–µ –º–æ–¥–µ–ª–µ–π –∏ —É—Å–∫–æ—Ä–µ–Ω–∏–µ inference",
        "–î–æ–≤–µ—Ä–µ–Ω–Ω—ã–π AI –æ–±—ä—è—Å–Ω–∏–º—ã–µ –∏ –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã",
        "AI –¥–ª—è –∫–ª–∏–º–∞—Ç–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è –∏ —ç–∫–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Ä–µ—à–µ–Ω–∏—è",
        "–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–∏—Ñ—Ä–æ–≤—ã–µ –ø–æ–º–æ—â–Ω–∏–∫–∏",
        "AI –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —É—á–µ–±–Ω—ã–µ –ø–ª–∞–Ω—ã",
    ]

    application_domains = [
        "–≤ –≤–µ–± —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏ cloud native –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö",
        "–≤ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∏ IoT —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–∞—Ö –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –∞–Ω–∞–ª–∏–∑–µ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –±–∏–∑–Ω–µ—Å –∞–Ω–∞–ª–∏—Ç–∏–∫–µ",
        "–≤ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –∫–∏–±–µ—Ä–∑–∞—â–∏—Ç–µ",
        "–≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ –∏ –±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö",
        "–≤ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ —Ñ–∏–Ω—Ç–µ—Ö–µ",
        "–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ smart city –∏ —É–º–Ω–æ–π –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–µ",
        "–≤ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –∏ EdTech",
    ]

    trend = random.choice(current_trends_2025)
    domain = random.choice(application_domains)

    formats = [
        f"–¢–µ–Ω–¥–µ–Ω—Ü–∏–∏ 2025 {trend} {domain}",
        f"{trend} {domain} –≤ 2025 –≥–æ–¥—É",
        f"{trend} —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è {domain} –≤ 2025",
        f"–ö–∞–∫ {trend} —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ—Ç {domain} –≤ 2025 –≥–æ–¥—É",
        f"–ò–Ω–Ω–æ–≤–∞—Ü–∏–∏ 2025 {trend} –¥–ª—è {domain}",
        f"{trend} –±—É–¥—É—â–µ–µ {domain} –≤ 2025 –≥–æ–¥—É",
        f"–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ {trend} –≤ {domain} 2025",
    ]
    return random.choice(formats)


# ======================== –ì–ï–ù–ï–†–ê–¶–ò–Ø –¢–ï–ö–°–¢–ê ========================

def generate_article_content(topic: str):
    openrouter_key = os.getenv("OPENROUTER_API_KEY")
    groq_key = os.getenv("GROQ_API_KEY")

    models_to_try = []

    # 1) OpenRouter –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
    if openrouter_key:
        log("üîë OpenRouter API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω")
        for m in [
            "anthropic/claude-3-haiku",
            "mistralai/mistral-7b-instruct",
            "meta-llama/llama-3-8b-instruct",
            "google/gemini-pro",
        ]:
            models_to_try.append(
                (f"OpenRouter-{m}", lambda model=m: generate_with_openrouter(openrouter_key, model, topic))
            )

    # 2) Groq ‚Äî –∑–∞–ø–∞—Å–Ω–æ–π
    if groq_key:
        log("üîë Groq API –∫–ª—é—á –Ω–∞–π–¥–µ–Ω")
        for m in [
            "llama-3.1-8b-instant",
            "llama-3.2-1b-preview",
            "llama-3.2-3b-preview",
            "mixtral-8x7b-32768",
            "gemma2-9b-it",
        ]:
            models_to_try.append(
                (f"Groq-{m}", lambda model=m: generate_with_groq(groq_key, model, topic))
            )

    # –ü–µ—Ä–µ–±–æ—Ä –º–æ–¥–µ–ª–µ–π
    for name, fn in models_to_try:
        try:
            log(f"üîÑ –ü—Ä–æ–±—É–µ–º: {name}")
            text = fn()
            if isinstance(text, str) and len(text.strip()) > 150:
                log(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —á–µ—Ä–µ–∑ {name}")
                return text.strip(), name
        except Exception as e:
            log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ {name}: {str(e)[:200]}")
            time.sleep(0.5)

    # Fallback ‚Äî –ø—Ä–æ—Å—Ç–∞—è –∑–∞–≥–æ—Ç–æ–≤–∫–∞
    log("‚ö†Ô∏è –í—Å–µ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback-–∫–æ–Ω—Ç–µ–Ω—Ç")
    content = f"""# {topic}

## –í–≤–µ–¥–µ–Ω–∏–µ
{topic} ‚Äî –æ–¥–Ω–æ –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –≤ 2025 –≥–æ–¥—É.

## –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã
- **–ú–æ–¥–µ–ª–∏**: —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ –∏ –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏  
- **–ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞**: –æ–±–ª–∞–∫–∞, edge-–≤—ã—á–∏—Å–ª–µ–Ω–∏—è, —É—Å–∫–æ—Ä–∏—Ç–µ–ª–∏

## –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ
- –ü—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç—å, —Ñ–∏–Ω—Ç–µ—Ö, –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å

## –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã
–ê–∫—Ü–µ–Ω—Ç –Ω–∞ —ç–Ω–µ—Ä–≥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å, –æ–±—ä—è—Å–Ω–∏–º–æ—Å—Ç—å, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å –ò–æ–¢.

## –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
{topic} —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –Ω–æ–≤—É—é —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é –Ω–æ—Ä–º—É –¥–ª—è –±–∏–∑–Ω–µ—Å–∞ –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤.
"""
    return content, "fallback"


def generate_with_openrouter(api_key: str, model_name: str, topic: str) -> str:
    prompt = f"""–ù–∞–ø–∏—à–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—É—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É: "{topic}".

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –û–±—ä–µ–º 500‚Äì800 —Å–ª–æ–≤
- –§–æ—Ä–º–∞—Ç Markdown —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ ##
- –Ø–∑—ã–∫: —Ä—É—Å—Å–∫–∏–π
- –°—Ç–∏–ª—å: —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π, –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∏ –ò–¢-–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–≤
- –§–æ–∫—É—Å –Ω–∞ 2025 –≥–æ–¥

–°—Ç—Ä—É–∫—Ç—É—Ä–∞:
1) –í–≤–µ–¥–µ–Ω–∏–µ –∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å
2) –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∏ —Ç–µ—Ö–Ω–∏–∫–∏ (–∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã, —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏)
3) –ö–µ–π—Å—ã –≤–Ω–µ–¥—Ä–µ–Ω–∏—è
4) –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è, —Ä–∏—Å–∫–∏ –∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
5) –ü–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –∏ –≤—ã–≤–æ–¥—ã

–ò—Å–ø–æ–ª—å–∑—É–π **–∂–∏—Ä–Ω—ã–π** –¥–ª—è —Ç–µ—Ä–º–∏–Ω–æ–≤, —Å–ø–∏—Å–∫–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã."""

    r = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers={
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
            "HTTP-Referer": "https://github.com/lybra-bee",
            "X-Title": "AI Blog Generator",
        },
        json={
            "model": model_name,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 1800,
            "temperature": 0.7,
        },
        timeout=60,
    )
    r.raise_for_status()
    data = r.json()
    return data["choices"][0]["message"]["content"]


def generate_with_groq(api_key: str, model_name: str, topic: str) -> str:
    prompt = f"""–ù–∞–ø–∏—à–∏ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—É—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É: "{topic}".

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- 500‚Äì800 —Å–ª–æ–≤, Markdown, –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏ ##
- –†—É—Å—Å–∫–∏–π —è–∑—ã–∫, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–∏–ª—å
- –ê—É–¥–∏—Ç–æ—Ä–∏—è: —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏, DevOps, –∞—Ä—Ö–∏—Ç–µ–∫—Ç—ã
- 2025 –≥–æ–¥, –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∏

–î–æ–±–∞–≤—å: **–∂–∏—Ä–Ω—ã–π** –¥–ª—è –∫–ª—é—á–µ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤, —Å–ø–∏—Å–∫–∏ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—Ä—ã."""

    r = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers={"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"},
        json={
            "model": model_name,
            "messages": [{"role": "user", "content": prompt}],
            "max_tokens": 1800,
            "temperature": 0.7,
            "top_p": 0.9,
        },
        timeout=60,
    )
    r.raise_for_status()
    data = r.json()
    return data["choices"][0]["message"]["content"]


# ======================== –ì–ï–ù–ï–†–ê–¶–ò–Ø –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø ========================

def generate_article_image(topic: str) -> str | None:
    """–ü—ã—Ç–∞–µ–º—Å—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏—é –∫ —Å—Ç–∞—Ç—å–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º web-–ø—É—Ç—å /images/posts/xxx.jpg"""
    prompt = generate_image_prompt(topic)
    slug = generate_slug(topic)
    STATIC_IMG_DIR.mkdir(parents=True, exist_ok=True)
    target_path = STATIC_IMG_DIR / f"{slug}.jpg"

    generators = [
        ("HuggingFace", lambda: generate_image_huggingface(prompt, target_path)),
        ("DeepAI",      lambda: generate_image_deepai(prompt, target_path)),
        ("Craiyon",     lambda: generate_image_craiyon(prompt, target_path)),
        ("Lexica",      lambda: fetch_image_lexica(prompt, target_path)),
        ("Picsum",      lambda: fetch_image_picsum(slug, target_path)),
    ]

    for name, fn in generators:
        try:
            log(f"üîÑ –ü—Ä–æ–±—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä: {name}")
            ok = fn()
            if ok and target_path.exists() and target_path.stat().st_size > 1024:
                log(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ {name}")
                return f"/images/posts/{target_path.name}"
            else:
                log(f"‚ö†Ô∏è {name} –≤–µ—Ä–Ω—É–ª None")
        except Exception as e:
            log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ {name}: {str(e)[:200]}")

    log("‚ùå –í—Å–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏ ‚Äî –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    return None


def generate_image_huggingface(prompt: str, out_path: Path) -> bool:
    """Hugging Face Inference API ‚Äî –ø–µ—Ä–µ–±–æ—Ä –º–æ–¥–µ–ª–µ–π; –∂–¥—ë–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏."""
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    for model in HF_IMAGE_MODELS:
        try:
            url = f"https://api-inference.huggingface.co/models/{model}"
            resp = requests.post(
                url,
                headers=headers,
                json={"inputs": prompt, "options": {"wait_for_model": True}},
                timeout=120,
            )
            # –ò–Ω–æ–≥–¥–∞ —Å–µ—Ä–≤–∏—Å –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç JSON-–æ—à–∏–±–∫—É
            ctype = resp.headers.get("content-type", "")
            if resp.status_code == 200 and "image" in ctype:
                out_path.write_bytes(resp.content)
                return True
            else:
                # –ü–æ–ø—Ä–æ–±—É–µ–º —Ä–∞–∑–æ–±—Ä–∞—Ç—å JSON, —á—Ç–æ–±—ã –ø–æ–Ω—è—Ç—å –ø—Ä–∏—á–∏–Ω—É
                try:
                    j = resp.json()
                    log(f"‚ÑπÔ∏è HF {model} –æ—Ç–≤–µ—Ç: {j}")
                except Exception:
                    log(f"‚ÑπÔ∏è HF {model} –∫–æ–Ω—Ç–µ–Ω—Ç-—Ç–∏–ø {ctype}, —Å—Ç–∞—Ç—É—Å {resp.status_code}")
        except requests.HTTPError as e:
            log(f"HF {model} HTTPError: {e}")
        except Exception as e:
            log(f"HF {model} error: {e}")
    return False


def generate_image_deepai(prompt: str, out_path: Path) -> bool:
    """DeepAI text2img (–±–µ—Å–ø–ª–∞—Ç–Ω—ã–µ –ª–∏–º–∏—Ç—ã –±—ã–≤–∞—é—Ç)."""
    try:
        url = "https://api.deepai.org/api/text2img"
        resp = requests.post(
            url,
            headers={"Api-Key": DEEPAI_API_KEY},
            data={"text": prompt},
            timeout=60,
        )
        if resp.status_code != 200:
            log(f"DeepAI HTTP {resp.status_code}: {resp.text[:200]}")
            return False
        data = resp.json()
        img_url = data.get("output_url") or data.get("id")  # –∏–Ω–æ–≥–¥–∞ –¥—Ä—É–≥–æ–π –∫–ª—é—á
        if not img_url:
            log(f"DeepAI: –Ω–µ –≤–µ—Ä–Ω—É–ª —Å—Å—ã–ª–∫—É: {data}")
            return False
        # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ —Å—Å—ã–ª–∫–µ
        r2 = requests.get(img_url, timeout=60)
        if r2.status_code == 200:
            out_path.write_bytes(r2.content)
            return True
        log(f"DeepAI download HTTP {r2.status_code}")
        return False
    except Exception as e:
        log(f"DeepAI error: {e}")
        return False


def generate_image_craiyon(prompt: str, out_path: Path) -> bool:
    """Craiyon (—á–∞—Å—Ç–æ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç/–±–ª–æ–∫–∏—Ä—É–µ—Ç). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç base64 –∫–∞—Ä—Ç–∏–Ω–∫—É."""
    try:
        url = "https://api.craiyon.com/v3/text-to-image"
        payload = {"prompt": prompt, "negative_prompt": "", "resolution": "1024x1024"}
        resp = requests.post(url, json=payload, timeout=120)
        if resp.status_code != 200:
            log(f"Craiyon HTTP {resp.status_code}: {resp.text[:200]}")
            return False
        data = resp.json()
        images_b64 = data.get("images") or []
        if not images_b64:
            return False
        img_bytes = base64.b64decode(images_b64[0])
        out_path.write_bytes(img_bytes)
        return True
    except Exception as e:
        log(f"Craiyon error: {e}")
        return False


def fetch_image_lexica(prompt: str, out_path: Path) -> bool:
    """Lexica ‚Äî –Ω–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è, –∞ –ø–æ–¥–±–æ—Ä –ø–æ—Ö–æ–∂–µ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ (–º–æ–∂–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å—Å—è Cloudflare)."""
    try:
        q = re.sub(r"\s+", "+", prompt.strip())[:200]
        url = f"https://lexica.art/api/v1/search?q={q}"
        resp = requests.get(url, timeout=60)
        if resp.status_code != 200:
            log(f"Lexica HTTP {resp.status_code}")
            return False
        data = resp.json()
        imgs = data.get("images") or []
        if not imgs:
            return False
        # –ë–µ—Ä—ë–º –ø–æ–ª–Ω–æ—Ä–∞–∑–º–µ—Ä–Ω—ã–π src
        src = imgs[0].get("src") or imgs[0].get("srcSmall")
        if not src:
            return False
        r2 = requests.get(src, timeout=60)
        if r2.status_code == 200:
            out_path.write_bytes(r2.content)
            return True
        log(f"Lexica download HTTP {r2.status_code}")
        return False
    except Exception as e:
        log(f"Lexica error: {e}")
        return False


def fetch_image_picsum(seed: str, out_path: Path) -> bool:
    """–ù–∞–¥—ë–∂–Ω—ã–π –ø–æ—Å–ª–µ–¥–Ω–∏–π fallback: —Å–ª—É—á–∞–π–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ seed."""
    try:
        url = f"https://picsum.photos/seed/{seed}/1024/1024"
        resp = requests.get(url, timeout=60)
        if resp.status_code == 200:
            out_path.write_bytes(resp.content)
            return True
        log(f"Picsum HTTP {resp.status_code}")
        return False
    except Exception as e:
        log(f"Picsum error: {e}")
        return False


def generate_image_prompt(topic: str) -> str:
    en = (
        f"Futuristic technology illustration for article about '{topic}'. "
        "Abstract neural networks, data flows, circuit patterns, holographic UI, "
        "clean corporate style, professional digital art, centered composition, "
        "high detail, 4k, no text, no watermark."
    )
    variants = [
        en,
        en + " Blue-purple palette, soft glow, cinematic lighting.",
        en + " Geometric shapes, depth of field, volumetric light.",
        en + " Cyberpunk accents, neon glows, high contrast.",
    ]
    return random.choice(variants)


# ======================== –°–ï–†–í–ò–°–ù–´–ï –§–£–ù–ö–¶–ò–ò ========================

def generate_slug(text: str) -> str:
    text = text.lower()
    text = text.replace(" ", "-")
    text = re.sub(r"[^a-z0-9\-]", "", text)  # —Ç–æ–ª—å–∫–æ ascii
    text = re.sub(r"-+", "-", text).strip("-")
    return text[:80] if text else "ai-2025"


def generate_frontmatter(title: str, content: str, model_used: str, image_url: str | None) -> str:
    now = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
    # –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è YAML
    safe_title = (
        title.replace(":", " -")
             .replace('"', "")
             .replace("'", "")
             .replace("\\", "")
             .strip()
    )
    lines = [
        "---",
        f'title: "{safe_title}"',
        f"date: {now}",
        "draft: false",
        'tags: ["AI", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ", "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "2025"]',
        'categories: ["–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"]',
        f'summary: "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è (–º–æ–¥–µ–ª—å: {model_used})"',
    ]
    if image_url:
        lines.append(f'image: "{image_url}"')
    lines.append("---")
    lines.append(content.strip())
    return "\n".join(lines) + "\n"


def clean_old_articles(keep_last: int = 3):
    log(f"üßπ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å—Ç–∞—Ç–µ–π, –æ—Å—Ç–∞–≤–ª—è–µ–º {keep_last} –ø–æ—Å–ª–µ–¥–Ω–∏—Ö...")
    try:
        POSTS_DIR.mkdir(parents=True, exist_ok=True)
        items = sorted(POSTS_DIR.glob("*.md"), key=lambda p: p.stat().st_mtime, reverse=True)
        if not items:
            log("üìÅ –ù–µ—Ç —Å—Ç–∞—Ç–µ–π –¥–ª—è –æ—á–∏—Å—Ç–∫–∏")
            return
        to_delete = items[keep_last:]
        log(f"üìä –í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π: {len(items)}")
        log(f"üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º: {len(items[:keep_last])}")
        log(f"üóëÔ∏è –£–¥–∞–ª—è–µ–º: {len(to_delete)}")
        for p in to_delete:
            try:
                p.unlink()
                log(f"‚ùå –£–¥–∞–ª–µ–Ω–æ: {p.name}")
            except Exception as e:
                log(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {p}: {e}")
    except Exception as e:
        log(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Å—Ç–∞—Ç–µ–π: {e}")


def cleanup_broken_news():
    """–£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã –≤ content/news, –∫–æ—Ç–æ—Ä—ã–µ –ª–æ–º–∞–ª–∏ Hugo –∏–∑-–∑–∞ YAML."""
    news_dir = Path("content/news")
    if not news_dir.exists():
        return
    removed = 0
    for md in news_dir.glob("*.md"):
        try:
            md.unlink()
            removed += 1
        except Exception:
            pass
    if removed:
        log(f"üßΩ –£–¥–∞–ª–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –≤ content/news: {removed}")


# ======================== –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ========================

if __name__ == "__main__":
    generate_content()
