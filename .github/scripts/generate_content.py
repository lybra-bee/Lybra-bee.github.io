#!/usr/bin/env python3
import os
import json
import requests
import random
from datetime import datetime, timezone
import glob
import time
import base64

# -----------------------
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–º—ã —Å—Ç–∞—Ç—å–∏
# -----------------------
def generate_ai_trend_topic():
    trends = [
        "Multimodal AI - –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∞—É–¥–∏–æ",
        "AI –∞–≥–µ–Ω—Ç—ã - –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á",
        "–ö–≤–∞–Ω—Ç–æ–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
        "–ù–µ–π—Ä–æ–º–æ—Ä—Ñ–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è - —ç–Ω–µ—Ä–≥–æ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã",
        "Generative AI - —Å–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ –∫–æ–¥–∞",
        "Edge AI - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ",
        "AI –¥–ª—è –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
        "–≠—Ç–∏—á–Ω—ã–π AI - –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ AI",
        "AI –≤ healthcare - –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∏ –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–µ–¥–∏—Ü–∏–Ω–∞",
        "–ê–≤—Ç–æ–Ω–æ–º–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã - —Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞ –∏ –±–µ—Å–ø–∏–ª–æ—Ç–Ω—ã–π —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç",
        "AI –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è - —É—Å–∫–æ—Ä–µ–Ω–∏–µ inference",
        "–î–æ–≤–µ—Ä–µ–Ω–Ω—ã–π AI - –æ–±—ä—è—Å–Ω–∏–º—ã–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã",
        "AI –¥–ª—è –∫–ª–∏–º–∞—Ç–∞ - –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —ç–Ω–µ—Ä–≥–æ–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è",
        "–ü–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–µ AI –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã",
        "AI –≤ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ - –∞–¥–∞–ø—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ"
    ]
    domains = [
        "–≤ –≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ –∏ cloud-native –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö",
        "–≤ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö –∏ IoT",
        "–≤ –æ–±–ª–∞—á–Ω—ã—Ö —Å–µ—Ä–≤–∏—Å–∞—Ö –∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ –∞–Ω–∞–ª–∏–∑–µ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö",
        "–≤ –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
        "–≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–µ",
        "–≤ —Ñ–∏–Ω—Ç–µ—Ö–µ",
        "–≤ –∞–≤—Ç–æ–Ω–æ–º–Ω—ã—Ö —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ã—Ö —Å–∏—Å—Ç–µ–º–∞—Ö",
        "–≤ smart city",
        "–≤ EdTech"
    ]
    trend = random.choice(trends)
    domain = random.choice(domains)
    return f"{trend} {domain} –≤ 2025 –≥–æ–¥—É"

# -----------------------
# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Å—Ç–∞—Ç–µ–π
# -----------------------
def clean_old_articles(keep_last=3):
    articles = glob.glob("content/posts/*.md")
    if not articles:
        return
    articles.sort(key=os.path.getmtime, reverse=True)
    for f in articles[keep_last:]:
        try:
            os.remove(f)
        except:
            pass

# -----------------------
# –°–ª–∞–≥ –¥–ª—è —Ñ–∞–π–ª–æ–≤
# -----------------------
def generate_slug(text):
    text = text.lower()
    text = ''.join(c if c.isalnum() or c==' ' else '-' for c in text)
    text = text.strip('- ')
    text = text.replace(' ', '-')
    while '--' in text:
        text = text.replace('--','-')
    return text[:100]

# -----------------------
# Frontmatter Hugo
# -----------------------
def generate_frontmatter(title, image_url):
    now = datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
    frontmatter = f"""---
title: "{title}"
date: "{now}"
draft: false
tags: ["AI","–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ","—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏","2025"]
categories: ["–ò—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç"]
summary: "–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è –æ {title}"
image: "{image_url}"
---
"""
    return frontmatter

# -----------------------
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ç–∞—Ç—å–∏ —á–µ—Ä–µ–∑ API
# -----------------------
def generate_article_content(topic):
    openrouter_key = os.getenv('OPENROUTER_API_KEY')
    groq_key = os.getenv('GROQ_API_KEY')
    
    models_to_try = []
    if groq_key:
        groq_models = ["llama-3.1-8b-instant"]
        for m in groq_models:
            models_to_try.append(lambda m=m: generate_with_groq(groq_key, m, topic))
    if openrouter_key:
        openrouter_models = ["anthropic/claude-3-haiku"]
        for m in openrouter_models:
            models_to_try.append(lambda m=m: generate_with_openrouter(openrouter_key, m, topic))
    
    for func in models_to_try:
        try:
            result = func()
            if result and len(result.strip())>100:
                return result
        except:
            continue
    # fallback
    return f"# {topic}\n\n–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–∞—Ç—å—è. –ö–æ–Ω—Ç–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ API."

def generate_with_groq(api_key, model_name, topic):
    prompt = f"–ù–∞–ø–∏—à–∏ —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É: {topic} (Markdown, —Ä—É—Å—Å–∫–∏–π, 400-600 —Å–ª–æ–≤)"
    resp = requests.post(
        "https://api.groq.com/openai/v1/chat/completions",
        headers={"Authorization": f"Bearer {api_key}","Content-Type":"application/json"},
        json={"model": model_name, "messages":[{"role":"user","content":prompt}],"max_tokens":1500}
    )
    data = resp.json()
    return data['choices'][0]['message']['content'].strip()

def generate_with_openrouter(api_key, model_name, topic):
    prompt = f"–ù–∞–ø–∏—à–∏ —Å—Ç–∞—Ç—å—é –Ω–∞ —Ç–µ–º—É: {topic} (Markdown, —Ä—É—Å—Å–∫–∏–π, 400-600 —Å–ª–æ–≤)"
    resp = requests.post(
        "https://openrouter.ai/api/v1/chat/completions",
        headers={"Authorization": f"Bearer {api_key}","Content-Type":"application/json"},
        json={"model": model_name, "messages":[{"role":"user","content":prompt}],"max_tokens":1500}
    )
    data = resp.json()
    return data['choices'][0]['message']['content'].strip()

# -----------------------
# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
# -----------------------
def generate_image_deepai(text_prompt):
    key = "98c841c4"  # —Ç–æ–∫–µ–Ω
    try:
        resp = requests.post(
            "https://api.deepai.org/api/text2img",
            data={"text": text_prompt},
            headers={"Api-Key": key},
            timeout=20
        )
        data = resp.json()
        return data.get("output_url")
    except:
        return None

def generate_image_craiyon(text_prompt):
    try:
        resp = requests.post(
            "https://api.craiyon.com/generate",
            json={"prompt": text_prompt},
            timeout=20
        )
        data = resp.json()
        images = data.get("images")
        if images:  # base64
            img_data = base64.b64decode(images[0])
            filename = "static/images/posts/temp_image.png"
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            with open(filename,'wb') as f:
                f.write(img_data)
            return "/images/posts/temp_image.png"
    except:
        return None

def generate_image_placeholder():
    return "/images/posts/placeholder.png"

# -----------------------
# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
# -----------------------
def generate_content():
    print("üöÄ –ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
    clean_old_articles()
    topic = generate_ai_trend_topic()
    print(f"üìù –¢–µ–º–∞: {topic}")
    
    content = generate_article_content(topic)
    
    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    image_url = generate_image_deepai(topic)
    if not image_url:
        image_url = generate_image_craiyon(topic)
    if not image_url:
        image_url = generate_image_placeholder()
    
    slug = generate_slug(topic)
    filename = f"content/posts/{datetime.now().strftime('%Y-%m-%d')}-{slug}.md"
    os.makedirs(os.path.dirname(filename), exist_ok=True)
    
    frontmatter = generate_frontmatter(topic, image_url)
    with open(filename,'w',encoding='utf-8') as f:
        f.write(frontmatter + "\n" + content)
    
    print(f"‚úÖ –°—Ç–∞—Ç—å—è —Å–æ–∑–¥–∞–Ω–∞: {filename}")
    return filename

# -----------------------
# –ó–∞–ø—É—Å–∫
# -----------------------
if __name__ == "__main__":
    generate_content()
